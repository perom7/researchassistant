{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh4YlkbDNxYC",
        "outputId": "e31011d0-b155-40f0-90f5-a0fbb4c1bc29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting tts\n",
            "  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from tts) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from tts) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from tts) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from tts) (2.5.1+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from tts) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from tts) (4.67.1)\n",
            "Collecting anyascii>=0.3.0 (from tts)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from tts) (3.11.12)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from tts) (3.1.0)\n",
            "Collecting pysbd>=0.3.4 (from tts)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from tts)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from tts)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from tts) (3.10.0)\n",
            "Collecting trainer>=0.0.32 (from tts)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from tts)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from tts) (0.42.1)\n",
            "Collecting pypinyin (from tts)\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from tts)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from tts)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from tts) (3.9.1)\n",
            "Collecting g2pkk>=0.1.1 (from tts)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from tts)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from tts)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from tts)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from tts) (4.48.3)\n",
            "Collecting encodec>=0.1.1 (from tts)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from tts)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from tts)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->tts) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tts) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.61.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (2.17.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->tts)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->tts) (1.18.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (1.9.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->tts) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->tts) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->tts)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->tts) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->tts) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->tts) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->tts) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (0.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.10.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.5.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->tts)\n",
            "  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->tts)\n",
            "  Downloading SudachiDict_core-20250129-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (3.17.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1->tts)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->tts) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->tts) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->tts) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (0.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (0.5.2)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->tts)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->tts) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->tts) (3.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->tts) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->tts) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->tts) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->tts) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->tts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->tts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->tts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->tts) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->tts) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->tts) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (4.25.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->tts) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (0.1.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl (937 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiDict_core-20250129-py3-none-any.whl (72.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=b4c93ba9c5afba0d5ba2490a8b51c9769dbe8925e67b75650ab6ef6845e45364\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=5c68384d3a899a973a4cb6474d54d30e8091bfbe0ecb4314ff413df35cebacf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=8ae9476e4e168202e93b15ee2fca392e8b7dac14a6e00afba62c653579b13271\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=73311579dd63f5476e1d4760ea3e343e22d13302c3d9b22ab1dc31c4ad11f4b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=d2d1271b6a5be45d785558b2a33271356f050113cf05a3dcdc8ebee3bda21229\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498313 sha256=41002daf95854068fffb9fbafcfee63e09a1ad883ed7cc44b64261cb9fcf31d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/fa/df/5fdf5d3cc26ba859b8698a1f28581d1a6aa081edc6df9847ab\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=0e4eb4e63ad2cd15e2c18eb2248215b8bb7b5578e91e8384876a3c9767b5d559\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/30/52/dc5cd222b4bbde285838fed1f96636e96f85cd75493e79a978\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=3a12f377989e43ae84154221071c29c2491f4a8cff8118dcf1d6bc89d76f8d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/eb/59/30b5d15e56347e595f613036cbea0f807ad9621c75cd75d912\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=cd42a5939dcedf3d8f939798f64d2cb9713db0a44c2e58c44c81f00190f885dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\n",
            "Successfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: sudachipy, pydub, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, python-crfsuite, pytesseract, pysbd, pypinyin, PyPDF2, pdf2image, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, num2words, networkx, jsonlines, gruut-ipa, coqpit, anyascii, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, g2pkk, dateparser, pynndescent, nvidia-cusolver-cu12, gruut, umap-learn, trainer, encodec, tts\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 networkx-2.8.8 num2words-0.5.14 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandas-1.5.3 pdf2image-1.17.0 pydub-0.25.1 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 pytesseract-0.3.13 python-crfsuite-0.9.11 sudachidict-core-20250129 sudachipy-0.6.10 trainer-0.0.36 tts-0.22.0 umap-learn-0.5.7 unidecode-1.3.8\n",
            "Collecting gTTs\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTs) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTs) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTs\n",
            "Successfully installed gTTs-2.5.4\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 pdf2image pytesseract pillow pydub tts\n",
        "from PyPDF2 import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import re\n",
        "!pip install gTTs\n",
        "import google.generativeai as genai\n",
        "import transformers\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from gtts import gTTS  # Using Google Text-to-Speech instead of OpenAI\n",
        "!pip install google-generativeai python-pptx\n",
        "\n",
        "import google.generativeai as genai\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "!pip install moviepy\n",
        "!pip install pydub\n",
        "\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gKMOVkPT6YX"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=\"API-KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqZi9l2nPURR"
      },
      "source": [
        "# **Text Extraction, Summary Generation and Simplification to Generate Scripts and Podcast**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjkXolZxSAy3"
      },
      "source": [
        "gemini_mahida wadi file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YWcy8qyiOHij"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    except:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        for img in images:\n",
        "            text += pytesseract.image_to_string(img)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
        "    return text\n",
        "\n",
        "def summarize_with_gemini(text):\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    prompt = \"\"\"Summarize this research paper for a non-expert audience in a well-structured paragraph format.\n",
        "    Do not use bullet points, numbering, asterisks, or bold text. Write naturally and cohesively while covering the key contributions, methodology, analysis, implications, limitations, and conclusion in a fluid and engaging manner.\n",
        "\n",
        "    Paper: \"\"\" + text[:30000]\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "def extract_key_concepts(text):\n",
        "    # Using same BERT model as before\n",
        "    nlp = transformers.pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "    entities = nlp(text)\n",
        "    keywords = [entity[\"word\"] for entity in entities if entity[\"entity\"] in [\"B-ORG\", \"B-MISC\"]]\n",
        "    return list(set(keywords))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DkiQ5m7BOp95"
      },
      "outputs": [],
      "source": [
        "def simplify_jargon(text):\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    prompt = \"\"\"Replace technical terms with simple analogies. Example:\n",
        "    \"Summary: This research paper is about optimizing resources in hospital departments through network slicing. The authors propose a method to assign individual network slices to each smart device in various hospital departments using a model named federated learning.\n",
        "\n",
        "In the methodology, the network is divided into three types: Enhanced Mobile Broadband (eMBB), Ultra-Reliable Low Latency Communication (URLLC), and Massive Machine Type Communication (mMTC). All this to consider aspects such as bandwidth, data transmission speed, the number of devices supported at a time, and reliability. The method uses federated learning to ensure the privacy of patient data, keeping it within the respective department and not shared with others.\n",
        "\n",
        "The results show that the model learns new patterns accurately (98% accuracy) with this real-time scenario-based approach leading to more efficient resource allocation. The results also show a consistent improvement in the accuracy rate and a decrease in the loss value with each round of learning, indicating the effectiveness of the model.\n",
        "\n",
        "However, the study's limitation is that it doesn't include encryption techniques, which could further improve the safety of the model. Also, it's based on the assumption that data from all devices is periodically transmitted to a local model, which may not always be the case in actual scenarios.\n",
        "\n",
        "In conclusion, the study proves the efficiency of federated learning and network slicing in smart healthcare facilities for optimizing resources and maintaining data privacy. The authors suggest that future research could enhance this model by integrating encryption techniques to improve patient data privacy even further.\" -> \"Simplified text: This research paper is like a recipe for a better-run hospital using individual lanes for each smart gadget in different hospital departments, similar to having different checkout lines for different types of groceries. The recipe uses a model called federated learning, which is like a private tutor for each department, ensuring that patient data stays within that department and isn't shared with others.\n",
        "\n",
        "The method splits the hospital's network into three types, like a highway with lanes for motorbikes, cars, and trucks, considering things like how wide the lanes are, how fast the vehicles can go, how many vehicles can fit in at a time, and how reliable the lanes are.\n",
        "\n",
        "The outcomes show that this recipe works really well, with the model learning new routines accurately (98% accuracy) with this real-world test, leading to a smoother run hospital department. The outcomes also show a continuous increase in success rate and a decrease in errors with each learning session, showing the recipe works well.\n",
        "\n",
        "However, the recipe's limitation is that it doesn't include a security guard (encryption techniques), which could make the model even safer. Also, it assumes that data from all gadgets is regularly sent to a local model, kind of like a department head, which may not always happen in real life.\n",
        "\n",
        "To sum up, the study shows that the recipe using federated learning and network slicing works well in smart hospitals for making things run more smoothly and keeping patient data private. The authors suggest that future research could add a security guard to the recipe to keep patient data even safer.\"\n",
        "    Text to simplify: \"\"\" + text\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "def generate_analogy(concept):\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    response = model.generate_content(f\"Create a relatable analogy for this concept: {concept}\")\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Fe2Dec_OuO8"
      },
      "outputs": [],
      "source": [
        "def generate_video_script(summary: str, analogy: str, video_type) -> str:\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    if video_type == \"reel\":\n",
        "        structure = f\"\"\"\n",
        "        - Hook (15 seconds): Grab attention with a surprising fact/question\n",
        "        - Problem (30 seconds): Explain the research gap\n",
        "        - Analogy (35 seconds): Simplify using {analogy}\n",
        "        - Impact (30 seconds): Why this matters\n",
        "        - Call-to-action (15 seconds)\n",
        "        \"\"\"\n",
        "    else:\n",
        "        structure = f\"\"\"\n",
        "        - Intro (30s): Context + thesis\n",
        "        - Methodology (90s): Non-technical explanation\n",
        "        - Key Findings (90s): Visualized results\n",
        "        - Real-World Example (60s): {analogy}\n",
        "        - Conclusion (30s)\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(\n",
        "        f\"Create a {video_type} script using this structure: {structure}\\n\"\n",
        "        f\"Content: {summary}\"\n",
        "    )\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N0Wxl7peOwTh"
      },
      "outputs": [],
      "source": [
        "def generate_podcast_script(summary: str, analogy: str) -> str:\n",
        "    \"\"\"Generate podcast script with explicit analogy explanations\"\"\"\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    prompt = f\"\"\"Create a podcast dialogue with these elements:\n",
        "    1. Host asks questions about the research\n",
        "    2. Expert explains concepts USING THIS ANALOGY: {analogy}\n",
        "    3. For each technical concept:\n",
        "       - First state the technical term\n",
        "       - Then explain using the analogy\n",
        "       - Finally connect back to the research\n",
        "\n",
        "    Format exactly like:\n",
        "    Host: [question]\n",
        "    Expert: \"[Technical concept] works similar to {analogy.split('→')[0].strip()}...\n",
        "    (Explain analogy connection)\n",
        "    This relates to our research because...\"\n",
        "\n",
        "    Include 5 question-answer pairs. Research summary: {summary[:15000]}\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        if not response.text:\n",
        "            raise ValueError(\"Empty response from Gemini\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return fallback_script(summary, analogy)\n",
        "\n",
        "def fallback_script(summary: str, analogy: str) -> str:\n",
        "    \"\"\"Guaranteed script with analogy explanation\"\"\"\n",
        "    base_analogy = analogy.split('→')[0].strip()\n",
        "    explanation = analogy.split('→')[1].strip()\n",
        "\n",
        "    return f\"\"\"\n",
        "    Host: Can you explain the core concept of this research?\n",
        "    Expert: Certainly! {base_analogy} works similar to {explanation}.\n",
        "    In this research, we've applied this principle to...\n",
        "\n",
        "    Host: What makes this approach effective?\n",
        "    Expert: Just like how {base_analogy} requires {explanation.split(' ')[0]},\n",
        "    our method needs...\n",
        "\n",
        "    Host: How does this compare to existing solutions?\n",
        "    Expert: Traditional approaches work like [old method], but our {base_analogy}-inspired\n",
        "    method {explanation}...\n",
        "\n",
        "    Host: What real-world applications do you envision?\n",
        "    Expert: Imagine using {base_analogy} for [application]. That's exactly how\n",
        "    {explanation} could transform...\n",
        "\n",
        "    Host: What's next for this research?\n",
        "    Expert: We're expanding the {base_analogy} analogy to explore [new area],\n",
        "    building on {explanation} fundamentals.\n",
        "    \"\"\"\n",
        "\n",
        "def generate_podcast_audio(script: str, output_path: str = \"podcast.mp3\") -> str:\n",
        "    \"\"\"Generate audio with explicit analogy handling\"\"\"\n",
        "    # Pre-process script\n",
        "    script = script.strip()\n",
        "    if not script:\n",
        "        script = fallback_script(\"\", \"Technical process → Simple analogy\")\n",
        "\n",
        "    # Split roles with validation\n",
        "    host_lines = []\n",
        "    expert_lines = []\n",
        "\n",
        "    for line in script.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"Host:\"):\n",
        "            host_lines.append(line.replace(\"Host:\", \"\").strip())\n",
        "        elif line.startswith(\"Expert:\"):\n",
        "            expert_content = line.replace(\"Expert:\", \"\").strip()\n",
        "            # Ensure analogy mention\n",
        "            if \"analogy\" not in expert_content.lower():\n",
        "                expert_content += f\" (using our core analogy: {analogy})\"\n",
        "            expert_lines.append(expert_content)\n",
        "\n",
        "    # Fallback if no lines found\n",
        "    if not host_lines:\n",
        "        host_lines = [\"Could you explain the main concept using your analogy?\"]\n",
        "    if not expert_lines:\n",
        "        expert_lines = [f\"The key analogy is: {analogy}. This means...\"]\n",
        "    print(host_lines)\n",
        "    print(expert_lines)\n",
        "    # Generate voices\n",
        "    try:\n",
        "        # Host voice\n",
        "        host_text = \" \".join(host_lines)\n",
        "        host_tts = gTTS(host_text, lang='en', slow=False)\n",
        "        host_tts.save(\"host_temp.mp3\")\n",
        "\n",
        "        # Expert voice (slower pace)\n",
        "        expert_text = \" \".join(expert_lines)\n",
        "        expert_tts = gTTS(expert_text, lang='en', slow=True)\n",
        "        expert_tts.save(\"expert_temp.mp3\")\n",
        "\n",
        "        # Combine audio\n",
        "        host_audio = AudioSegment.from_mp3(\"host_temp.mp3\")\n",
        "        expert_audio = AudioSegment.from_mp3(\"expert_temp.mp3\")\n",
        "        combined = host_audio + AudioSegment.silent(500) + expert_audio\n",
        "        combined.export(output_path, format=\"mp3\")\n",
        "\n",
        "    finally:\n",
        "        # Cleanup\n",
        "        for f in [\"host_temp.mp3\", \"expert_temp.mp3\"]:\n",
        "            if os.path.exists(f):\n",
        "                os.remove(f)\n",
        "\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "suowMNsIO6pu",
        "outputId": "deca985a-1abc-4ccc-eefc-1618447bd993"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This paper presents a novel framework for Healthcare IoT (H-IoT) networks that combines quantum communication, edge intelligence, and machine learning for secure and efficient data transmission.\n",
            "\n",
            "**Methodology:**\n",
            "The framework utilizes a four-layer architecture:\n",
            "1. **Wearable Health Edge Layer:** Collects real-time patient data from wearable sensors.\n",
            "2. **Network Intrusion Detection Layer:** Detects network intrusions using machine learning models, with Random Forest (RF) found to be most effective.\n",
            "3. **Quantum Layer:** Employs quantum cryptographic protocols (BB84 and E91) to encrypt healthcare data, ensuring data security and integrity.\n",
            "4. **Hospital Layer:** Receives and processes secure healthcare data, facilitating real-time monitoring and enhancing patient safety.\n",
            "\n",
            "**Analysis:**\n",
            "The framework was evaluated on a dataset of network traffic related to Wireless Body Area Networks (WBANs). RF outperformed other machine learning models in detecting intrusions, achieving an accuracy of 90.51%. Using quantum cryptography enhanced data security and enabled seamless communication between medical devices and healthcare systems.\n",
            "\n",
            "**Implications:**\n",
            "The proposed framework addresses critical challenges in H-IoT networks, including data security, network intrusion detection, and real-time communication. By incorporating quantum communication and edge intelligence, it ensures data privacy, integrity, and improves healthcare delivery efficiency.\n",
            "\n",
            "**Limitations:**\n",
            "The framework relies on the availability of quantum communication technology, which may not be widely accessible in all healthcare settings. Additionally, the computational overhead of quantum cryptography may need to be further optimized for real-time applications.\n",
            "\n",
            "**Conclusion:**\n",
            "The quantum communication-based edge intelligence framework provides a secure and efficient solution for H-IoT networks, enhancing patient care and healthcare delivery. Future research aims to optimize the framework's performance, explore the use of additional quantum cryptographic protocols, and consider the practical implementation challenges in healthcare environments.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Simplified Text:**\n",
            "\n",
            "Imagine a smart hospital with wearable devices that track patients' health. This information is like a valuable treasure that needs to be kept safe.\n",
            "\n",
            "To protect this treasure, we have a team of experts (edge intelligence) who use special computers (machine learning) to search for \"bad guys\" (network intrusions). Like a super spy, they use a secret code (quantum cryptography) to keep the treasure safe.\n",
            "\n",
            "The treasure is then sent to the hospital's headquarters (hospital layer), where it's used to make sure patients are safe.\n",
            "\n",
            "This system has been tested, and it's like a superhero with a 90% success rate at catching the \"bad guys.\" And it uses the secret code to keep the treasure safe.\n",
            "\n",
            "This system helps hospitals run more smoothly, protect patient information, and improve healthcare. But it's still like a new invention that needs some improvements, like making sure it can be used in every hospital and finding ways to make it work even faster.\n",
            "\n",
            "In the future, we'll make it even better by adding more secret codes and finding ways to make it run even smoother.\n"
          ]
        }
      ],
      "source": [
        "paper_text = extract_text_from_pdf(\"/content/Lakshit___Quantum__Riya__Param.pdf\")\n",
        "clean_text = preprocess_text(paper_text)\n",
        "summary = summarize_with_gemini(clean_text)\n",
        "print(summary)\n",
        "keywords = extract_key_concepts(clean_text)\n",
        "simplified_text = simplify_jargon(summary)\n",
        "print(simplified_text)\n",
        "analogy = generate_analogy(\"Generative Adversarial Networks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rjYxHcULPDBR",
        "outputId": "87d5126b-ab58-4447-c3da-45b4e8ebcd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Script:\n",
            " Host: Could you elaborate on the role of Generative Adversarial Networks (GANs) in H-IoT networks?\n",
            "\n",
            "Expert: GANs follow a concept similar to Generative Adversarial Networks (GANs): The Art Studio Analogy.\n",
            "\n",
            "Imagine an artist's studio with two students:\n",
            "\n",
            " Generator (Alice): A talented painter who can create beautiful artwork but lacks the skill to distinguish between a masterpiece and a forgery.\n",
            " Discriminator (Bob): A highly experienced art critic who can quickly spot the difference between a genuine masterpiece and a fake.\n",
            "\n",
            "GAN Process:\n",
            "\n",
            " Training: Alice (Generator) paints countless variations of artwork. Bob (Discriminator) evaluates each one, giving feedback to Alice about what distinguishes real from fake.\n",
            " Iteration: Alice uses Bob's feedback to improve her painting skills, gradually creating artwork that becomes indistinguishable from real paintings.\n",
            " Outcome: In the end, Alice becomes so skilled that her paintings fool even Bob, the expert.\n",
            "\n",
            "How it Relates to GANs:\n",
            "\n",
            " Generator: The Generator in GANs is like Alice, creating plausible data samples (e.g., images, text).\n",
            " Discriminator: The Discriminator is like Bob, evaluating the generated samples and providing feedback to the Generator.\n",
            " Training: The training process mirrors the interaction between Alice and Bob, as the Generator learns to produce more realistic samples.\n",
            " Result: GANs eventually generate data samples so convincing that they can deceive even experts in the field.\n",
            "\n",
            "Just as Alice becomes a master painter under Bob's guidance, GANs allow machine learning models to generate remarkably authentic and diverse data that can be used for various applications....\n",
            "    \n",
            "Explanation: GANs can be used in H-IoT networks to generate synthetic healthcare data, which can be used to train machine learning models and improve the performance of intrusion detection systems. This can help to ensure the security and privacy of H-IoT networks.\n",
            "    \n",
            "Connection to Research: Our research utilizes GANs to generate synthetic network traffic data, which is used to train the Random Forest machine learning model for network intrusion detection in H-IoT networks.\n",
            "\n",
            "Host: How does the Random Forest (RF) machine learning model contribute to the framework?\n",
            "\n",
            "Expert: RF in our framework functions similar to Generative Adversarial Networks (GANs): The Art Studio Analogy.\n",
            "\n",
            "Imagine an artist's studio with two students:\n",
            "\n",
            " Generator (Alice): A talented painter who can create beautiful artwork but lacks the skill to distinguish between a masterpiece and a forgery.\n",
            " Discriminator (Bob): A highly experienced art critic who can quickly spot the difference between a genuine masterpiece and a fake.\n",
            "\n",
            "GAN Process:\n",
            "\n",
            " Training: Alice (Generator) paints countless variations of artwork. Bob (Discriminator) evaluates each one, giving feedback to Alice about what distinguishes real from fake.\n",
            " Iteration: Alice uses Bob's feedback to improve her painting skills, gradually creating artwork that becomes indistinguishable from real paintings.\n",
            " Outcome: In the end, Alice becomes so skilled that her paintings fool even Bob, the expert.\n",
            "\n",
            "How it Relates to GANs:\n",
            "\n",
            " Generator: The Generator in GANs is like Alice, creating plausible data samples (e.g., images, text).\n",
            " Discriminator: The Discriminator is like Bob, evaluating the generated samples and providing feedback to the Generator.\n",
            " Training: The training process mirrors the interaction between Alice and Bob, as the Generator learns to produce more realistic samples.\n",
            " Result: GANs eventually generate data samples so convincing that they can deceive even experts in the field.\n",
            "\n",
            "Just as Alice becomes a master painter under Bob's guidance, GANs allow machine learning models to generate remarkably authentic and diverse data that can be used for various applications....\n",
            "    \n",
            "Explanation: RF is a machine learning algorithm that can be used to classify network traffic. In our framework, RF is used to detect network intrusions in H-IoT networks. RF is particularly well-suited for this task because it can handle large and complex datasets.\n",
            "    \n",
            "Connection to Research: Our research investigates the use of RF as a machine learning model for network intrusion detection in H-IoT networks. We evaluate RF against other machine learning models and demonstrate its superior performance in terms of accuracy and efficiency.\n",
            "\n",
            "Host: How does the framework address data security and privacy concerns in H-IoT networks?\n",
            "\n",
            "Expert: The Quantum Layer in our framework operates like Generative Adversarial Networks (GANs): The Art Studio Analogy.\n",
            "\n",
            "Imagine an artist's studio with two students:\n",
            "\n",
            " Generator (Alice): A talented painter who can create beautiful artwork but lacks the skill to distinguish between a masterpiece and a forgery.\n",
            " Discriminator (Bob): A highly experienced art critic who can quickly spot the difference between a genuine masterpiece and a fake.\n",
            "\n",
            "GAN Process:\n",
            "\n",
            " Training: Alice (Generator) paints countless variations of artwork. Bob (Discriminator) evaluates each one, giving feedback to Alice about what distinguishes real from fake.\n",
            " Iteration: Alice uses Bob's feedback to improve her painting skills, gradually creating artwork that becomes indistinguishable from real paintings.\n",
            " Outcome: In the end, Alice becomes so skilled that her paintings fool even Bob, the expert.\n",
            "\n",
            "How it Relates to GANs:\n",
            "\n",
            " Generator: The Generator in GANs is like Alice, creating plausible data samples (e.g., images, text).\n",
            " Discriminator: The Discriminator is like Bob, evaluating the generated samples and providing feedback to the Generator.\n",
            " Training: The training process mirrors the interaction between Alice and Bob, as the Generator learns to produce more realistic samples.\n",
            " Result: GANs eventually generate data samples so convincing that they can deceive even experts in the field.\n",
            "\n",
            "Just as Alice becomes a master painter under Bob's guidance, GANs allow machine learning models to generate remarkably authentic and diverse data that can be used for various applications....\n",
            "    \n",
            "Explanation: The Quantum Layer employs quantum cryptographic protocols to encrypt healthcare data, ensuring data security and integrity. Quantum cryptography is based on the principles of quantum mechanics, which makes it highly secure and resistant to eavesdropping.\n",
            "    \n",
            "Connection to Research: Our research incorporates quantum cryptography into the H-IoT framework to ensure the security and privacy of healthcare data. We demonstrate the effectiveness of quantum cryptography in protecting H-IoT data from unauthorized access and eavesdropping.\n",
            "\n",
            "Host: What are the potential applications of the quantum communication-based edge intelligence framework in healthcare?\n",
            "\n",
            "Expert: The quantum communication-based edge intelligence framework finds applications like Generative Adversarial Networks (GANs): The Art Studio Analogy.\n",
            "\n",
            "Imagine an artist's studio with two students:\n",
            "\n",
            " Generator (Alice): A talented painter who can create beautiful artwork but lacks the skill to distinguish between a masterpiece and a forgery.\n",
            " Discriminator (Bob): A highly experienced art critic who can quickly spot the difference between a genuine masterpiece and a fake.\n",
            "\n",
            "GAN Process:\n",
            "\n",
            " Training: Alice (Generator) paints countless variations of artwork. Bob (Discriminator) evaluates each one, giving feedback to Alice about what distinguishes real from fake.\n",
            " Iteration: Alice uses Bob's feedback to improve her painting skills, gradually creating artwork that becomes indistinguishable from real paintings.\n",
            " Outcome: In the end, Alice becomes so skilled that her paintings fool even Bob, the expert.\n",
            "\n",
            "How it Relates to GANs:\n",
            "\n",
            " Generator: The Generator in GANs is like Alice, creating plausible data samples (e.g., images, text).\n",
            " Discriminator: The Discriminator is like Bob, evaluating the generated samples and providing feedback to the Generator.\n",
            " Training: The training process mirrors the interaction between Alice and Bob, as the Generator learns to produce more realistic samples.\n",
            " Result: GANs eventually generate data samples so convincing that they can deceive even experts in the field.\n",
            "\n",
            "Just as Alice becomes a master painter under Bob's guidance, GANs allow machine learning models to generate remarkably authentic and diverse data that can be used for various applications....\n",
            "    \n",
            "Explanation: The quantum communication-based edge intelligence framework has various applications in healthcare, including:\n",
            "\n",
            " Secure transmission of patient data\n",
            " Real-time monitoring of patients\n",
            " Early detection of diseases\n",
            " Personalized medicine\n",
            " Enhanced drug discovery\n",
            "    \n",
            "Connection to Research: Our research demonstrates the potential applications of the quantum communication-based edge intelligence framework in healthcare. We showcase use cases and provide experimental results to validate the framework's effectiveness in various healthcare scenarios.\n",
            "['Could you elaborate on the role of Generative Adversarial Networks (GANs) in H-IoT networks?', 'How does the Random Forest (RF) machine learning model contribute to the framework?', 'How does the framework address data security and privacy concerns in H-IoT networks?', 'What are the potential applications of the quantum communication-based edge intelligence framework in healthcare?']\n",
            "['GANs follow a concept similar to Generative Adversarial Networks (GANs): The Art Studio Analogy.', 'RF in our framework functions similar to Generative Adversarial Networks (GANs): The Art Studio Analogy.', 'The Quantum Layer in our framework operates like Generative Adversarial Networks (GANs): The Art Studio Analogy.', 'The quantum communication-based edge intelligence framework finds applications like Generative Adversarial Networks (GANs): The Art Studio Analogy.']\n",
            "Podcast saved to: podcast.mp3\n"
          ]
        }
      ],
      "source": [
        "script = generate_podcast_script(summary, analogy)\n",
        "script = script.replace(\"*\", \"\").replace(\"\", \"\")\n",
        "print(\"Generated Script:\\n\", script)\n",
        "audio_file = generate_podcast_audio(script)\n",
        "print(\"Podcast saved to:\", audio_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWYZNsY1QJ4k"
      },
      "source": [
        "# **PPT Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KlLj7LWpQoO1"
      },
      "outputs": [],
      "source": [
        "# Define theme styles\n",
        "THEMES = {\n",
        "    \"formal\": {\n",
        "        \"title_font\": \"Times New Roman\",\n",
        "        \"title_size\": Pt(44),\n",
        "        \"title_color\": RGBColor(0,0,0),  # Black\n",
        "        \"title_bold\": True,\n",
        "        \"title_all_caps\": True,\n",
        "        \"body_font\": \"Times New Roman\",\n",
        "        \"body_size\": Pt(20),\n",
        "        \"body_color\": RGBColor(92, 64, 51),  # Black\n",
        "        \"background_color\": RGBColor(196, 164, 132),  # Gray\n",
        "    },\n",
        "    \"casual\": {\n",
        "        \"title_font\": \"Comic Sans MS\",\n",
        "        \"title_size\": Pt(40),\n",
        "        \"title_color\": RGBColor(255, 165, 0),  # Blue\n",
        "        \"body_font\": \"Segoe Script\",\n",
        "        \"body_size\": Pt(18),\n",
        "        \"body_color\": RGBColor(0,0,0),  # Black\n",
        "        \"background_color\": RGBColor(237,232,208),  # Light yellow\n",
        "    },\n",
        "    \"fun\": {\n",
        "        \"title_font\": \"Impact\",\n",
        "        \"title_size\": Pt(48),\n",
        "        \"title_color\": RGBColor(136, 8, 8),  # Pink\n",
        "        \"body_font\": \"Verdana\",\n",
        "        \"body_size\": Pt(22),\n",
        "        \"body_color\": RGBColor(0,0,0),  # Black\n",
        "        \"background_color\": RGBColor(186,225,255),  # Light green\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sfqIAOSAQb_n"
      },
      "outputs": [],
      "source": [
        "def generate_slides_content(summary):\n",
        "    \"\"\"\n",
        "    Generates structured PowerPoint slide content using Gemini API.\n",
        "    Returns formatted text with slide titles and bullet points.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Create an 8-slide PowerPoint presentation from this research paper summary.\n",
        "    Ensure every slide follows this structure:\n",
        "\n",
        "    Slide 1: Title Slide\n",
        "    - **Title**: [Research Paper Title]\n",
        "    - **Presented by:**: \"Presented by: Deep Drillers\"\n",
        "\n",
        "    Slide 2: Introduction\n",
        "    - Background of the study\n",
        "    - Research objectives\n",
        "    - Key questions addressed\n",
        "\n",
        "    Slide 3: Methodology\n",
        "    - Research design\n",
        "    - Data collection methods\n",
        "    - Analysis techniques\n",
        "\n",
        "    Slide 4: Key Findings\n",
        "    - Main result 1\n",
        "    - Main result 2\n",
        "    - Main result 3\n",
        "\n",
        "    Slide 5: Analysis\n",
        "    - Interpretation of results\n",
        "    - Comparison with previous work\n",
        "    - Statistical significance\n",
        "\n",
        "    Slide 6: Implications\n",
        "    - Theoretical implications\n",
        "    - Practical applications\n",
        "    - Policy recommendations\n",
        "\n",
        "    Slide 7: Limitations\n",
        "    - Study limitations 1\n",
        "    - Study limitations 2\n",
        "    - Future research directions\n",
        "\n",
        "    Slide 8: Conclusion\n",
        "    - Summary of key points\n",
        "    - Final remarks\n",
        "    - Acknowledgments\n",
        "\n",
        "    Paper Summary: {summary}\n",
        "\n",
        "    **Ensure slides are formatted with 'Slide X: Title' followed by bullet points ('- ').**\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    slide_content = response.text.strip()  # Ensure clean formatting\n",
        "\n",
        "    # Remove the asterisks from the slide content\n",
        "    slide_content = slide_content.replace(\"**\", \"\")\n",
        "\n",
        "    print(\"Generated Slide Content:\\n\", slide_content)\n",
        "    return slide_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qbIQOXNSQk6r"
      },
      "outputs": [],
      "source": [
        "def parse_ai_content(ai_output):\n",
        "    \"\"\"Convert raw AI text output to structured format\"\"\"\n",
        "    slides = []\n",
        "    current_slide = {\"title\": \"\", \"bullets\": []}\n",
        "\n",
        "    for line in ai_output.split(\"\\n\"):\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"Slide\"):\n",
        "            if current_slide[\"title\"]:\n",
        "                slides.append(current_slide)\n",
        "                current_slide = {\"title\": \"\", \"bullets\": []}\n",
        "            current_slide[\"title\"] = line.split(\": \")[1]\n",
        "        elif line.startswith(\"-\"):\n",
        "            current_slide[\"bullets\"].append(line[2:])\n",
        "\n",
        "    if current_slide[\"title\"]:\n",
        "        slides.append(current_slide)\n",
        "\n",
        "    return slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sPExrEd8QODk"
      },
      "outputs": [],
      "source": [
        "def create_presentation(content, theme_name, filename=\"research_presentation.pptx\"):\n",
        "    \"\"\"Main function to create a PowerPoint presentation with a selected theme\"\"\"\n",
        "    # Parse raw AI content\n",
        "    structured_content = parse_ai_content(content)\n",
        "\n",
        "    # Create a blank presentation\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Get the selected theme\n",
        "    theme = THEMES.get(theme_name, THEMES[\"formal\"])  # Default to \"formal\" if theme not found\n",
        "\n",
        "    # Create slides\n",
        "    for slide_data in structured_content:\n",
        "        slide = prs.slides.add_slide(prs.slide_layouts[1])  # Use a blank slide layout\n",
        "        title = slide.shapes.title\n",
        "        title.text = slide_data[\"title\"].upper() if theme.get(\"title_all_caps\", False) else slide_data[\"title\"]\n",
        "        title.text_frame.paragraphs[0].font.name = theme[\"title_font\"]\n",
        "        title.text_frame.paragraphs[0].font.size = theme[\"title_size\"]\n",
        "        title.text_frame.paragraphs[0].font.color.rgb = theme[\"title_color\"]\n",
        "        title.text_frame.paragraphs[0].font.bold = theme.get(\"title_bold\", False)\n",
        "\n",
        "        content_box = slide.shapes.placeholders[1]\n",
        "        for bullet in slide_data[\"bullets\"]:\n",
        "            p = content_box.text_frame.add_paragraph()\n",
        "            p.text = bullet\n",
        "            p.level = 0\n",
        "            p.font.name = theme[\"body_font\"]\n",
        "            p.font.size = theme[\"body_size\"]\n",
        "            p.font.color.rgb = theme[\"body_color\"]\n",
        "\n",
        "        # Set slide background color\n",
        "        background = slide.background\n",
        "        fill = background.fill\n",
        "        fill.solid()\n",
        "        fill.fore_color.rgb = theme[\"background_color\"]\n",
        "\n",
        "    # Add footer\n",
        "    for slide in prs.slides:\n",
        "        txBox = slide.shapes.add_textbox(Inches(0.5), Inches(6.8), Inches(9), Inches(0.4))  # Adjusted position and size\n",
        "        tf = txBox.text_frame\n",
        "        tf.text = \"Made by DesAI\"\n",
        "        tf.paragraphs[0].font.size = Pt(12)\n",
        "        tf.paragraphs[0].font.color.rgb = RGBColor(150, 150, 150)  # Gray\n",
        "        tf.paragraphs[0].alignment = 1  # Center alignment\n",
        "\n",
        "    # Save the presentation\n",
        "    prs.save(filename)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jMfUKSBgQvV6",
        "outputId": "07827944-22c0-472d-8730-18a88bc8ca74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select a theme for your presentation:\n",
            "1. Formal\n",
            "2. Casual\n",
            "3. Fun\n",
            "Enter the number corresponding to your choice (1/2/3): 3\n",
            "Generating slide content...\n",
            "Generated Slide Content:\n",
            " Slide 1: Title Slide\n",
            "\n",
            "- Title: Retrieval Augmented Generative AI Chatbot for Healthcare\n",
            "- Presented by: Deep Drillers\n",
            "\n",
            "Slide 2: Introduction\n",
            "\n",
            "- Background: Generative AI in healthcare has limitations (\"productivity paradox\")\n",
            "- Research objectives: Develop a RAG AI Chatbot framework to overcome these limitations\n",
            "- Key questions addressed: Can RAG enhance consultation summaries, diagnostic insights, and emotion assessments?\n",
            "\n",
            "Slide 3: Methodology\n",
            "\n",
            "- Research design: Data-driven framework integrating multiple modules\n",
            "- Data collection methods: Pre-existing medical knowledge databases\n",
            "- Analysis techniques: Machine learning models, natural language processing\n",
            "\n",
            "Slide 4: Key Findings\n",
            "\n",
            "- Main result 1: Comprehensive patient summaries with clinical entities highlighted\n",
            "- Main result 2: ML-based disease diagnosis predictions and emotion profiles\n",
            "- Main result 3: Emotion transition detection and insights for patient care\n",
            "\n",
            "Slide 5: Analysis\n",
            "\n",
            "- Interpretation of results: Framework demonstrated capabilities in information processing and emotion detection\n",
            "- Comparison with previous work: Novel approach integrating advanced AI techniques\n",
            "- Statistical significance: Validated with sample dataset\n",
            "\n",
            "Slide 6: Implications\n",
            "\n",
            "- Theoretical implications: Advancements in AI for healthcare\n",
            "- Practical applications: Improved decision-making, patient engagement\n",
            "- Policy recommendations: Framework adoption for enhanced healthcare services\n",
            "\n",
            "Slide 7: Limitations\n",
            "\n",
            "- Study limitations 1: Limited dataset size for testing\n",
            "- Study limitations 2: Absence of multi-modal data integration\n",
            "- Future research directions: Expand data types, conduct field tests for validation\n",
            "\n",
            "Slide 8: Conclusion\n",
            "\n",
            "- Summary of key points: RAG AI Chatbot framework addresses productivity paradox in healthcare\n",
            "- Final remarks: Potential to transform patient care through innovative AI solutions\n",
            "- Acknowledgments: Recognition of contributors and support\n",
            "Content generated!\n",
            "\n",
            "Creating presentation...\n",
            "Presentation saved as research_presentation.pptx\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7c94c850-406a-4e00-86fe-61de3851fc46\", \"research_presentation.pptx\", 37436)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Ask the user to select a theme\n",
        "    print(\"Select a theme for your presentation:\")\n",
        "    print(\"1. Formal\")\n",
        "    print(\"2. Casual\")\n",
        "    print(\"3. Fun\")\n",
        "    theme_choice = input(\"Enter the number corresponding to your choice (1/2/3): \").strip()\n",
        "\n",
        "    # Map user input to theme name\n",
        "    theme_mapping = {\"1\": \"formal\", \"2\": \"casual\", \"3\": \"fun\"}\n",
        "    chosen_theme = theme_mapping.get(theme_choice, \"formal\")  # Default to \"formal\" if invalid input\n",
        "\n",
        "    paper_summary = summary\n",
        "    # Generate slide content\n",
        "    print(\"Generating slide content...\")\n",
        "    content = generate_slides_content(paper_summary)\n",
        "    print(\"Content generated!\\n\")\n",
        "\n",
        "    # Create PowerPoint\n",
        "    print(\"Creating presentation...\")\n",
        "    output_file = create_presentation(content, chosen_theme)\n",
        "    print(f\"Presentation saved as {output_file}\")\n",
        "\n",
        "    # If using Google Colab, download the file\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(output_file)\n",
        "    except ImportError:\n",
        "        print(\"Run this in Colab to download the file automatically.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1RfhUP4RYWz"
      },
      "source": [
        "# **Video Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHNSwi87Rcc_",
        "outputId": "66eade0c-89ff-4e34-a5e1-0ab2c19b2198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video output/output_video_1.mp4.\n",
            "MoviePy - Writing audio in output_video_1TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output/output_video_1.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output/output_video_1.mp4\n"
          ]
        }
      ],
      "source": [
        "def process_videos(video_files, audio_file, output_dir=\"output\"):\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Load the audio file\n",
        "    audio_clip = AudioFileClip(audio_file)\n",
        "    audio_duration = audio_clip.duration\n",
        "\n",
        "    for i, video_file in enumerate(video_files):\n",
        "        # Load the video file\n",
        "        video_clip = VideoFileClip(video_file)\n",
        "\n",
        "        # Cut the video to the duration of the audio\n",
        "        video_clip = video_clip.subclip(0, min(video_clip.duration, audio_duration))\n",
        "\n",
        "        # If the video has its own audio, mix it with the provided audio\n",
        "        if video_clip.audio is not None:\n",
        "            final_audio = CompositeAudioClip([video_clip.audio, audio_clip])\n",
        "        else:\n",
        "            final_audio = audio_clip\n",
        "\n",
        "        # Set the final audio to the video\n",
        "        final_clip = video_clip.set_audio(final_audio)\n",
        "\n",
        "        # Save the final video\n",
        "        output_file = os.path.join(output_dir, f\"output_video_{i+1}.mp4\")\n",
        "        final_clip.write_videofile(output_file, codec=\"libx264\")\n",
        "\n",
        "        # Close the clips to free up resources\n",
        "        video_clip.close()\n",
        "        final_clip.close()\n",
        "\n",
        "    audio_clip.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # List of video files (you can modify this to upload files via a GUI or other means)\n",
        "    #video_files = [\"video1.mp4\", \"video2.mp4\", \"video3.mp4\", \"video4.mp4\", \"video5.mp4\"]\n",
        "\n",
        "    # Audio file to overlap with the videos\n",
        "    audio_file = \"/content/podcast.mp3\"\n",
        "\n",
        "    # Process the videos\n",
        "    process_videos([\"/content/video.mp4\"], audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9zmvfrZxA-7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
