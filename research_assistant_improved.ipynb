{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edc34bc",
   "metadata": {},
   "source": [
    "## **1. Setup and Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q PyPDF2 pdf2image pytesseract pillow pydub gTTS\n",
    "!pip install -q google-generativeai python-pptx\n",
    "!pip install -q moviepy\n",
    "!pip install -q transformers torch\n",
    "\n",
    "print(\"‚úì All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PDF and text processing\n",
    "from PyPDF2 import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# AI and NLP\n",
    "import google.generativeai as genai\n",
    "import transformers\n",
    "\n",
    "# Audio processing\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# PowerPoint\n",
    "from pptx import Presentation\n",
    "from pptx.util import Pt, Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "\n",
    "# Video processing\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8d03f",
   "metadata": {},
   "source": [
    "## **2. Configuration Management**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the Research Assistant\"\"\"\n",
    "    \n",
    "    # API Configuration\n",
    "    gemini_api_key: str = \"\"\n",
    "    \n",
    "    # Output directories\n",
    "    output_dir: Path = Path(\"output\")\n",
    "    audio_dir: Path = Path(\"output/audio\")\n",
    "    video_dir: Path = Path(\"output/video\")\n",
    "    ppt_dir: Path = Path(\"output/presentations\")\n",
    "    \n",
    "    # Processing parameters\n",
    "    max_text_length: int = 30000\n",
    "    summary_style: str = \"detailed\"  # Options: brief, detailed, technical\n",
    "    \n",
    "    # Audio settings\n",
    "    audio_language: str = \"en\"\n",
    "    audio_slow: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Create directories if they don't exist\"\"\"\n",
    "        for directory in [self.output_dir, self.audio_dir, self.video_dir, self.ppt_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def configure_gemini(self):\n",
    "        \"\"\"Configure Gemini API\"\"\"\n",
    "        if not self.gemini_api_key:\n",
    "            raise ValueError(\"Gemini API key not set!\")\n",
    "        genai.configure(api_key=self.gemini_api_key)\n",
    "        logger.info(\"‚úì Gemini API configured\")\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# Set your API key here\n",
    "config.gemini_api_key = \"YOUR_API_KEY_HERE\"  # Replace with your actual API key\n",
    "config.configure_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22268283",
   "metadata": {},
   "source": [
    "## **3. Text Extraction Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26452074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFExtractor:\n",
    "    \"\"\"Enhanced PDF text extraction with fallback mechanisms\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_text(pdf_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF with OCR fallback\"\"\"\n",
    "        logger.info(f\"Extracting text from: {pdf_path}\")\n",
    "        \n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Try standard extraction first\n",
    "            reader = PdfReader(pdf_path)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                page_text = page.extract_text()\n",
    "                if page_text.strip():\n",
    "                    text += page_text + \"\\n\"\n",
    "            \n",
    "            # If no text extracted, use OCR\n",
    "            if len(text.strip()) < 100:\n",
    "                logger.info(\"Standard extraction yielded little text, trying OCR...\")\n",
    "                text = PDFExtractor._ocr_extract(pdf_path)\n",
    "            \n",
    "            logger.info(f\"‚úì Extracted {len(text)} characters\")\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in text extraction: {e}\")\n",
    "            logger.info(\"Attempting OCR fallback...\")\n",
    "            return PDFExtractor._ocr_extract(pdf_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _ocr_extract(pdf_path: str) -> str:\n",
    "        \"\"\"Extract text using OCR\"\"\"\n",
    "        try:\n",
    "            images = convert_from_path(pdf_path)\n",
    "            text = \"\"\n",
    "            for i, img in enumerate(images):\n",
    "                logger.info(f\"OCR processing page {i+1}/{len(images)}\")\n",
    "                text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OCR extraction failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess extracted text\"\"\"\n",
    "        # Remove page numbers and headers\n",
    "        text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
    "        text = re.sub(r'\\d+\\s*\\n', '', text)  # Remove standalone page numbers\n",
    "        \n",
    "        # Remove excessive whitespace\n",
    "        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        \n",
    "        # Remove special characters that might cause issues\n",
    "        text = text.replace('\\x00', '')\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "# Test the extractor\n",
    "print(\"‚úì PDF Extractor module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93e5ba",
   "metadata": {},
   "source": [
    "## **4. AI Processing Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiProcessor:\n",
    "    \"\"\"Enhanced Gemini API processor with retry logic\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'gemini-pro'):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "        self.generation_config = genai.GenerationConfig(\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "            max_output_tokens=8192,\n",
    "        )\n",
    "    \n",
    "    def generate_content(self, prompt: str, max_retries: int = 3) -> str:\n",
    "        \"\"\"Generate content with retry logic\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=self.generation_config\n",
    "                )\n",
    "                return response.text.strip()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "        return \"\"\n",
    "    \n",
    "    def summarize_research_paper(self, text: str, style: str = \"detailed\") -> str:\n",
    "        \"\"\"Generate research paper summary with improved prompt\"\"\"\n",
    "        \n",
    "        style_instructions = {\n",
    "            \"brief\": \"Provide a concise 200-300 word summary focusing only on the main contribution and key findings.\",\n",
    "            \"detailed\": \"Provide a comprehensive 500-700 word summary covering all major aspects.\",\n",
    "            \"technical\": \"Provide a detailed technical summary preserving important terminology and methodological details.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert research paper analyst. {style_instructions.get(style, style_instructions['detailed'])}\n",
    "\n",
    "Structure your summary as a cohesive narrative covering:\n",
    "1. Research Context & Problem Statement\n",
    "2. Novel Contribution & Approach\n",
    "3. Methodology & Experimental Design\n",
    "4. Key Results & Analysis\n",
    "5. Implications & Impact\n",
    "6. Limitations & Future Work\n",
    "\n",
    "Write in clear, flowing paragraphs. Avoid bullet points, asterisks, or formatting markers.\n",
    "Make it accessible to someone with general scientific literacy but not necessarily expertise in the specific field.\n",
    "\n",
    "Research Paper:\n",
    "{text[:config.max_text_length]}\n",
    "\"\"\"\n",
    "        \n",
    "        logger.info(\"Generating summary...\")\n",
    "        summary = self.generate_content(prompt)\n",
    "        logger.info(f\"‚úì Summary generated ({len(summary)} characters)\")\n",
    "        return summary\n",
    "    \n",
    "    def simplify_with_analogies(self, text: str) -> str:\n",
    "        \"\"\"Simplify technical text using analogies\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert at explaining complex concepts through relatable analogies.\n",
    "\n",
    "Transform the following technical summary into an accessible explanation using:\n",
    "- Everyday analogies (compare to familiar objects, processes, or experiences)\n",
    "- Simple language (8th-grade reading level)\n",
    "- Concrete examples rather than abstract concepts\n",
    "- Progressive explanation (build from simple to complex)\n",
    "\n",
    "Maintain accuracy while making it engaging and memorable.\n",
    "\n",
    "Technical Summary:\n",
    "{text}\n",
    "\n",
    "Simplified Explanation:\n",
    "\"\"\"\n",
    "        \n",
    "        logger.info(\"Simplifying text with analogies...\")\n",
    "        simplified = self.generate_content(prompt)\n",
    "        logger.info(\"‚úì Text simplified\")\n",
    "        return simplified\n",
    "    \n",
    "    def generate_core_analogy(self, concept: str) -> str:\n",
    "        \"\"\"Generate a specific analogy for a core concept\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Create a clear, relatable analogy for this concept: {concept}\n",
    "\n",
    "Format:\n",
    "[Concept] is like [Familiar Thing] because [Explanation]\n",
    "\n",
    "Make it memorable and accurate. Use one of these analogy types:\n",
    "- Physical object comparison\n",
    "- Process/workflow comparison  \n",
    "- Social/organizational comparison\n",
    "- Natural phenomenon comparison\n",
    "\"\"\"\n",
    "        \n",
    "        return self.generate_content(prompt)\n",
    "\n",
    "# Initialize processor\n",
    "gemini = GeminiProcessor()\n",
    "print(\"‚úì Gemini Processor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2f562",
   "metadata": {},
   "source": [
    "## **5. Podcast Generation Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastGenerator:\n",
    "    \"\"\"Enhanced podcast script and audio generation\"\"\"\n",
    "    \n",
    "    def __init__(self, gemini_processor: GeminiProcessor):\n",
    "        self.gemini = gemini_processor\n",
    "    \n",
    "    def generate_script(self, summary: str, analogy: str, num_exchanges: int = 5) -> Dict[str, List[str]]:\n",
    "        \"\"\"Generate structured podcast script\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Create an engaging podcast dialogue between a Host and an Expert researcher.\n",
    "\n",
    "Structure: {num_exchanges} question-answer exchanges\n",
    "\n",
    "Requirements:\n",
    "1. Host asks insightful questions that build understanding progressively\n",
    "2. Expert explains using the provided analogy: {analogy}\n",
    "3. Each exchange should:\n",
    "   - Start conversational and engaging\n",
    "   - Use the analogy to clarify technical concepts\n",
    "   - Connect back to real-world applications\n",
    "4. Include natural transitions between topics\n",
    "\n",
    "Format each line EXACTLY as:\n",
    "Host: [question]\n",
    "Expert: [answer using analogy]\n",
    "\n",
    "Research Summary:\n",
    "{summary[:15000]}\n",
    "\n",
    "Generate {num_exchanges} exchanges:\n",
    "\"\"\"\n",
    "        \n",
    "        logger.info(\"Generating podcast script...\")\n",
    "        script_text = self.gemini.generate_content(prompt)\n",
    "        \n",
    "        # Parse script into structured format\n",
    "        script = self._parse_script(script_text)\n",
    "        \n",
    "        # Validate script\n",
    "        if not script['host'] or not script['expert']:\n",
    "            logger.warning(\"Script parsing failed, using fallback\")\n",
    "            script = self._generate_fallback_script(summary, analogy)\n",
    "        \n",
    "        logger.info(f\"‚úì Script generated: {len(script['host'])} exchanges\")\n",
    "        return script\n",
    "    \n",
    "    def _parse_script(self, script_text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Parse script text into structured format\"\"\"\n",
    "        host_lines = []\n",
    "        expert_lines = []\n",
    "        \n",
    "        for line in script_text.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Host:\"):\n",
    "                host_lines.append(line.replace(\"Host:\", \"\").strip())\n",
    "            elif line.startswith(\"Expert:\"):\n",
    "                expert_lines.append(line.replace(\"Expert:\", \"\").strip())\n",
    "        \n",
    "        return {'host': host_lines, 'expert': expert_lines}\n",
    "    \n",
    "    def _generate_fallback_script(self, summary: str, analogy: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Generate a basic fallback script\"\"\"\n",
    "        return {\n",
    "            'host': [\n",
    "                \"Welcome to our research podcast! Can you explain what this study is about?\",\n",
    "                \"That's fascinating! What was the main challenge you were trying to solve?\",\n",
    "                \"How did you approach this problem?\",\n",
    "                \"What were the key findings?\",\n",
    "                \"What does this mean for the future?\"\n",
    "            ],\n",
    "            'expert': [\n",
    "                f\"Let me explain using this analogy: {analogy}. {summary[:200]}...\",\n",
    "                f\"The main challenge relates to how {analogy.split()[0]} works...\",\n",
    "                \"Our approach was systematic and data-driven...\",\n",
    "                \"We discovered several important insights...\",\n",
    "                \"This research opens up exciting new possibilities...\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def generate_audio(self, script: Dict[str, List[str]], output_path: str) -> str:\n",
    "        \"\"\"Generate podcast audio from script\"\"\"\n",
    "        logger.info(\"Generating podcast audio...\")\n",
    "        \n",
    "        audio_segments = []\n",
    "        temp_files = []\n",
    "        \n",
    "        try:\n",
    "            # Generate audio for each exchange\n",
    "            for i, (host_line, expert_line) in enumerate(zip(script['host'], script['expert'])):\n",
    "                # Host audio (slightly faster)\n",
    "                host_file = f\"temp_host_{i}.mp3\"\n",
    "                host_tts = gTTS(host_line, lang=config.audio_language, slow=False)\n",
    "                host_tts.save(host_file)\n",
    "                temp_files.append(host_file)\n",
    "                \n",
    "                # Expert audio (normal pace)\n",
    "                expert_file = f\"temp_expert_{i}.mp3\"\n",
    "                expert_tts = gTTS(expert_line, lang=config.audio_language, slow=config.audio_slow)\n",
    "                expert_tts.save(expert_file)\n",
    "                temp_files.append(expert_file)\n",
    "                \n",
    "                # Load and combine\n",
    "                host_audio = AudioSegment.from_mp3(host_file)\n",
    "                expert_audio = AudioSegment.from_mp3(expert_file)\n",
    "                \n",
    "                # Add pause between speakers\n",
    "                audio_segments.append(host_audio)\n",
    "                audio_segments.append(AudioSegment.silent(duration=800))  # 0.8 second pause\n",
    "                audio_segments.append(expert_audio)\n",
    "                audio_segments.append(AudioSegment.silent(duration=1200))  # 1.2 second pause\n",
    "            \n",
    "            # Combine all segments\n",
    "            final_audio = sum(audio_segments)\n",
    "            \n",
    "            # Export\n",
    "            final_audio.export(output_path, format=\"mp3\")\n",
    "            logger.info(f\"‚úì Podcast audio saved: {output_path}\")\n",
    "            \n",
    "            return output_path\n",
    "            \n",
    "        finally:\n",
    "            # Cleanup temp files\n",
    "            for temp_file in temp_files:\n",
    "                if os.path.exists(temp_file):\n",
    "                    os.remove(temp_file)\n",
    "\n",
    "# Initialize generator\n",
    "podcast_gen = PodcastGenerator(gemini)\n",
    "print(\"‚úì Podcast Generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5196bb",
   "metadata": {},
   "source": [
    "## **6. PowerPoint Generation Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme definitions\n",
    "THEMES = {\n",
    "    \"professional\": {\n",
    "        \"title_font\": \"Calibri\",\n",
    "        \"title_size\": Pt(44),\n",
    "        \"title_color\": RGBColor(31, 78, 121),\n",
    "        \"title_bold\": True,\n",
    "        \"body_font\": \"Calibri\",\n",
    "        \"body_size\": Pt(18),\n",
    "        \"body_color\": RGBColor(64, 64, 64),\n",
    "        \"background_color\": RGBColor(255, 255, 255),\n",
    "        \"accent_color\": RGBColor(68, 114, 196)\n",
    "    },\n",
    "    \"modern\": {\n",
    "        \"title_font\": \"Arial\",\n",
    "        \"title_size\": Pt(40),\n",
    "        \"title_color\": RGBColor(47, 84, 150),\n",
    "        \"title_bold\": True,\n",
    "        \"body_font\": \"Arial\",\n",
    "        \"body_size\": Pt(16),\n",
    "        \"body_color\": RGBColor(89, 89, 89),\n",
    "        \"background_color\": RGBColor(248, 248, 248),\n",
    "        \"accent_color\": RGBColor(255, 192, 0)\n",
    "    },\n",
    "    \"creative\": {\n",
    "        \"title_font\": \"Georgia\",\n",
    "        \"title_size\": Pt(42),\n",
    "        \"title_color\": RGBColor(192, 80, 77),\n",
    "        \"title_bold\": True,\n",
    "        \"body_font\": \"Georgia\",\n",
    "        \"body_size\": Pt(18),\n",
    "        \"body_color\": RGBColor(79, 79, 79),\n",
    "        \"background_color\": RGBColor(252, 248, 227),\n",
    "        \"accent_color\": RGBColor(142, 169, 219)\n",
    "    }\n",
    "}\n",
    "\n",
    "class PowerPointGenerator:\n",
    "    \"\"\"Enhanced PowerPoint presentation generator\"\"\"\n",
    "    \n",
    "    def __init__(self, gemini_processor: GeminiProcessor):\n",
    "        self.gemini = gemini_processor\n",
    "    \n",
    "    def generate_content(self, summary: str, num_slides: int = 8) -> str:\n",
    "        \"\"\"Generate structured slide content\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Create a {num_slides}-slide PowerPoint presentation from this research paper summary.\n",
    "\n",
    "Required Structure:\n",
    "Slide 1: Title Slide\n",
    "- Title: [Concise research title]\n",
    "- Subtitle: [Key focus area]\n",
    "- Presented by: Deep Drillers\n",
    "\n",
    "Slide 2: Research Context\n",
    "- Problem statement\n",
    "- Motivation\n",
    "- Research gap\n",
    "\n",
    "Slide 3: Objectives & Approach\n",
    "- Primary objectives (3-4 points)\n",
    "- Research questions\n",
    "- Overall approach\n",
    "\n",
    "Slide 4: Methodology\n",
    "- Research design\n",
    "- Data sources/collection\n",
    "- Analysis methods\n",
    "\n",
    "Slide 5: Key Findings\n",
    "- Finding 1 (with metric if available)\n",
    "- Finding 2 (with metric if available)\n",
    "- Finding 3 (with metric if available)\n",
    "\n",
    "Slide 6: Analysis & Discussion\n",
    "- Interpretation of results\n",
    "- Comparison with existing work\n",
    "- Unexpected insights\n",
    "\n",
    "Slide 7: Impact & Applications\n",
    "- Theoretical contributions\n",
    "- Practical applications\n",
    "- Future research directions\n",
    "\n",
    "Slide 8: Conclusion\n",
    "- Main takeaways (3 points)\n",
    "- Limitations\n",
    "- Closing statement\n",
    "\n",
    "Format Requirements:\n",
    "- Start each slide with \"Slide N: [Title]\"\n",
    "- Use bullet points (start with \"- \")\n",
    "- Keep bullets concise (max 15 words each)\n",
    "- No asterisks or special formatting\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\"\"\"\n",
    "        \n",
    "        logger.info(\"Generating presentation content...\")\n",
    "        content = self.gemini.generate_content(prompt)\n",
    "        content = content.replace(\"**\", \"\").replace(\"*\", \"\")\n",
    "        logger.info(\"‚úì Presentation content generated\")\n",
    "        return content\n",
    "    \n",
    "    def create_presentation(self, content: str, theme_name: str, output_path: str) -> str:\n",
    "        \"\"\"Create PowerPoint presentation with theme\"\"\"\n",
    "        logger.info(f\"Creating presentation with '{theme_name}' theme...\")\n",
    "        \n",
    "        # Parse content\n",
    "        slides_data = self._parse_content(content)\n",
    "        \n",
    "        if not slides_data:\n",
    "            raise ValueError(\"Failed to parse presentation content\")\n",
    "        \n",
    "        # Get theme\n",
    "        theme = THEMES.get(theme_name, THEMES[\"professional\"])\n",
    "        \n",
    "        # Create presentation\n",
    "        prs = Presentation()\n",
    "        prs.slide_width = Inches(10)\n",
    "        prs.slide_height = Inches(7.5)\n",
    "        \n",
    "        for i, slide_data in enumerate(slides_data):\n",
    "            self._add_slide(prs, slide_data, theme)\n",
    "            logger.info(f\"  Added slide {i+1}/{len(slides_data)}\")\n",
    "        \n",
    "        # Add footer to all slides\n",
    "        self._add_footer(prs, theme)\n",
    "        \n",
    "        # Save\n",
    "        prs.save(output_path)\n",
    "        logger.info(f\"‚úì Presentation saved: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    def _parse_content(self, content: str) -> List[Dict[str, any]]:\n",
    "        \"\"\"Parse content into structured slide data\"\"\"\n",
    "        slides = []\n",
    "        current_slide = {\"title\": \"\", \"bullets\": []}\n",
    "        \n",
    "        for line in content.split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith(\"Slide\") and \":\" in line:\n",
    "                if current_slide[\"title\"]:\n",
    "                    slides.append(current_slide)\n",
    "                    current_slide = {\"title\": \"\", \"bullets\": []}\n",
    "                \n",
    "                # Extract title\n",
    "                title_part = line.split(\": \", 1)\n",
    "                if len(title_part) > 1:\n",
    "                    current_slide[\"title\"] = title_part[1]\n",
    "            \n",
    "            elif line.startswith(\"-\") and line[1:].strip():\n",
    "                current_slide[\"bullets\"].append(line[1:].strip())\n",
    "        \n",
    "        if current_slide[\"title\"]:\n",
    "            slides.append(current_slide)\n",
    "        \n",
    "        return slides\n",
    "    \n",
    "    def _add_slide(self, prs: Presentation, slide_data: Dict, theme: Dict):\n",
    "        \"\"\"Add a slide to the presentation\"\"\"\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "        \n",
    "        # Set background\n",
    "        background = slide.background\n",
    "        fill = background.fill\n",
    "        fill.solid()\n",
    "        fill.fore_color.rgb = theme[\"background_color\"]\n",
    "        \n",
    "        # Add title\n",
    "        title = slide.shapes.title\n",
    "        title.text = slide_data[\"title\"]\n",
    "        title_frame = title.text_frame\n",
    "        title_para = title_frame.paragraphs[0]\n",
    "        title_para.font.name = theme[\"title_font\"]\n",
    "        title_para.font.size = theme[\"title_size\"]\n",
    "        title_para.font.color.rgb = theme[\"title_color\"]\n",
    "        title_para.font.bold = theme[\"title_bold\"]\n",
    "        \n",
    "        # Add content\n",
    "        if len(slide.shapes.placeholders) > 1:\n",
    "            content_box = slide.shapes.placeholders[1]\n",
    "            text_frame = content_box.text_frame\n",
    "            text_frame.clear()\n",
    "            \n",
    "            for bullet in slide_data[\"bullets\"]:\n",
    "                p = text_frame.add_paragraph()\n",
    "                p.text = bullet\n",
    "                p.level = 0\n",
    "                p.font.name = theme[\"body_font\"]\n",
    "                p.font.size = theme[\"body_size\"]\n",
    "                p.font.color.rgb = theme[\"body_color\"]\n",
    "    \n",
    "    def _add_footer(self, prs: Presentation, theme: Dict):\n",
    "        \"\"\"Add footer to all slides\"\"\"\n",
    "        for slide in prs.slides:\n",
    "            footer = slide.shapes.add_textbox(\n",
    "                Inches(0.5), Inches(7), Inches(9), Inches(0.3)\n",
    "            )\n",
    "            text_frame = footer.text_frame\n",
    "            p = text_frame.paragraphs[0]\n",
    "            p.text = \"Generated by Research Assistant | Powered by Gemini AI\"\n",
    "            p.font.size = Pt(10)\n",
    "            p.font.color.rgb = RGBColor(128, 128, 128)\n",
    "            p.alignment = 1  # Center\n",
    "\n",
    "# Initialize generator\n",
    "ppt_gen = PowerPointGenerator(gemini)\n",
    "print(\"‚úì PowerPoint Generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fdc24d",
   "metadata": {},
   "source": [
    "## **7. Video Processing Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    \"\"\"Enhanced video processing with audio overlay\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_video(video_path: str, audio_path: str, output_path: str) -> str:\n",
    "        \"\"\"Add audio overlay to video\"\"\"\n",
    "        logger.info(f\"Processing video: {video_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load video and audio\n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = AudioFileClip(audio_path)\n",
    "            \n",
    "            # Adjust video duration to match audio\n",
    "            audio_duration = audio_clip.duration\n",
    "            \n",
    "            if video_clip.duration < audio_duration:\n",
    "                # Loop video if it's shorter than audio\n",
    "                num_loops = int(audio_duration / video_clip.duration) + 1\n",
    "                video_clip = video_clip.loop(n=num_loops)\n",
    "            \n",
    "            # Cut to audio duration\n",
    "            video_clip = video_clip.subclip(0, audio_duration)\n",
    "            \n",
    "            # Mix audio if video has original audio\n",
    "            if video_clip.audio is not None:\n",
    "                # Lower original audio volume\n",
    "                original_audio = video_clip.audio.volumex(0.2)\n",
    "                final_audio = CompositeAudioClip([original_audio, audio_clip])\n",
    "            else:\n",
    "                final_audio = audio_clip\n",
    "            \n",
    "            # Set audio to video\n",
    "            final_clip = video_clip.set_audio(final_audio)\n",
    "            \n",
    "            # Write output\n",
    "            final_clip.write_videofile(\n",
    "                output_path,\n",
    "                codec=\"libx264\",\n",
    "                audio_codec=\"aac\",\n",
    "                temp_audiofile=\"temp_audio.m4a\",\n",
    "                remove_temp=True\n",
    "            )\n",
    "            \n",
    "            # Cleanup\n",
    "            video_clip.close()\n",
    "            audio_clip.close()\n",
    "            final_clip.close()\n",
    "            \n",
    "            logger.info(f\"‚úì Video processed: {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Video processing error: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_process_videos(video_paths: List[str], audio_path: str, output_dir: str) -> List[str]:\n",
    "        \"\"\"Process multiple videos with the same audio\"\"\"\n",
    "        output_paths = []\n",
    "        \n",
    "        for i, video_path in enumerate(video_paths):\n",
    "            output_path = os.path.join(output_dir, f\"output_video_{i+1}.mp4\")\n",
    "            try:\n",
    "                VideoProcessor.process_video(video_path, audio_path, output_path)\n",
    "                output_paths.append(output_path)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to process {video_path}: {e}\")\n",
    "        \n",
    "        return output_paths\n",
    "\n",
    "print(\"‚úì Video Processor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bff066",
   "metadata": {},
   "source": [
    "## **8. Main Processing Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9108b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistant:\n",
    "    \"\"\"Main orchestration class for research paper processing\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.pdf_extractor = PDFExtractor()\n",
    "        self.gemini = GeminiProcessor()\n",
    "        self.podcast_gen = PodcastGenerator(self.gemini)\n",
    "        self.ppt_gen = PowerPointGenerator(self.gemini)\n",
    "    \n",
    "    def process_paper(self, pdf_path: str, generate_all: bool = True) -> Dict[str, str]:\n",
    "        \"\"\"Complete processing pipeline for a research paper\"\"\"\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Starting research paper processing\")\n",
    "        logger.info(f\"{'='*60}\\n\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. Extract text\n",
    "            logger.info(\"[1/6] Extracting text from PDF...\")\n",
    "            raw_text = self.pdf_extractor.extract_text(pdf_path)\n",
    "            clean_text = self.pdf_extractor.preprocess_text(raw_text)\n",
    "            results['text'] = clean_text\n",
    "            \n",
    "            # 2. Generate summary\n",
    "            logger.info(\"[2/6] Generating summary...\")\n",
    "            summary = self.gemini.summarize_research_paper(\n",
    "                clean_text,\n",
    "                style=self.config.summary_style\n",
    "            )\n",
    "            results['summary'] = summary\n",
    "            \n",
    "            # Save summary\n",
    "            summary_path = self.config.output_dir / \"summary.txt\"\n",
    "            with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(summary)\n",
    "            logger.info(f\"  Summary saved: {summary_path}\")\n",
    "            \n",
    "            # 3. Generate simplified version\n",
    "            logger.info(\"[3/6] Creating simplified explanation...\")\n",
    "            simplified = self.gemini.simplify_with_analogies(summary)\n",
    "            results['simplified'] = simplified\n",
    "            \n",
    "            # Save simplified version\n",
    "            simplified_path = self.config.output_dir / \"simplified.txt\"\n",
    "            with open(simplified_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(simplified)\n",
    "            logger.info(f\"  Simplified version saved: {simplified_path}\")\n",
    "            \n",
    "            # 4. Generate core analogy\n",
    "            logger.info(\"[4/6] Generating core analogy...\")\n",
    "            # Extract main concept from first paragraph\n",
    "            first_para = summary.split('\\n')[0]\n",
    "            analogy = self.gemini.generate_core_analogy(first_para[:200])\n",
    "            results['analogy'] = analogy\n",
    "            logger.info(f\"  Analogy: {analogy[:100]}...\")\n",
    "            \n",
    "            if generate_all:\n",
    "                # 5. Generate podcast\n",
    "                logger.info(\"[5/6] Generating podcast...\")\n",
    "                script = self.podcast_gen.generate_script(summary, analogy)\n",
    "                results['podcast_script'] = script\n",
    "                \n",
    "                # Save script\n",
    "                script_path = self.config.audio_dir / \"podcast_script.json\"\n",
    "                with open(script_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(script, f, indent=2)\n",
    "                logger.info(f\"  Script saved: {script_path}\")\n",
    "                \n",
    "                # Generate audio\n",
    "                audio_path = self.config.audio_dir / \"podcast.mp3\"\n",
    "                self.podcast_gen.generate_audio(script, str(audio_path))\n",
    "                results['podcast_audio'] = str(audio_path)\n",
    "                \n",
    "                # 6. Generate presentation\n",
    "                logger.info(\"[6/6] Generating PowerPoint presentation...\")\n",
    "                ppt_content = self.ppt_gen.generate_content(summary)\n",
    "                ppt_path = self.config.ppt_dir / \"presentation.pptx\"\n",
    "                self.ppt_gen.create_presentation(\n",
    "                    ppt_content,\n",
    "                    \"professional\",\n",
    "                    str(ppt_path)\n",
    "                )\n",
    "                results['presentation'] = str(ppt_path)\n",
    "            \n",
    "            logger.info(f\"\\n{'='*60}\")\n",
    "            logger.info(\"‚úì Processing complete!\")\n",
    "            logger.info(f\"{'='*60}\\n\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Processing failed: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize assistant\n",
    "assistant = ResearchAssistant(config)\n",
    "print(\"‚úì Research Assistant initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044aff78",
   "metadata": {},
   "source": [
    "## **9. Usage Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646828c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your PDF path\n",
    "PDF_PATH = \"/content/your_paper.pdf\"  # Change this to your PDF path\n",
    "\n",
    "# Process the paper\n",
    "results = assistant.process_paper(PDF_PATH, generate_all=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÑ Summary Length: {len(results['summary'])} characters\")\n",
    "print(f\"\\nüìù Simplified Version Length: {len(results['simplified'])} characters\")\n",
    "print(f\"\\nüéØ Core Analogy: {results['analogy']}\")\n",
    "\n",
    "if 'podcast_audio' in results:\n",
    "    print(f\"\\nüéôÔ∏è Podcast Audio: {results['podcast_audio']}\")\n",
    "if 'presentation' in results:\n",
    "    print(f\"\\nüìä Presentation: {results['presentation']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af024e",
   "metadata": {},
   "source": [
    "## **10. Optional: Generate Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have video files and want to add the podcast audio\n",
    "VIDEO_PATH = \"/content/your_video.mp4\"  # Change this\n",
    "AUDIO_PATH = results.get('podcast_audio', '')\n",
    "\n",
    "if AUDIO_PATH and os.path.exists(VIDEO_PATH):\n",
    "    output_video = config.video_dir / \"final_video.mp4\"\n",
    "    VideoProcessor.process_video(VIDEO_PATH, AUDIO_PATH, str(output_video))\n",
    "    print(f\"‚úì Video with audio overlay: {output_video}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Video or audio not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ccd06",
   "metadata": {},
   "source": [
    "## **11. Download Files (Colab Only)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download generated files in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Downloading generated files...\")\n",
    "    \n",
    "    # Download podcast\n",
    "    if 'podcast_audio' in results:\n",
    "        files.download(results['podcast_audio'])\n",
    "    \n",
    "    # Download presentation\n",
    "    if 'presentation' in results:\n",
    "        files.download(results['presentation'])\n",
    "    \n",
    "    print(\"‚úì Downloads complete!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - files saved to output directory\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
